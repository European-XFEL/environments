# European XFEL Environment Management

This repository contains Conda environment specifications and lock files
defining the environments provided for users at EuXFEL.

All environments contain **only** Conda packages, as installing packages via pip
into a Conda environment leads to inconsistencies.

If a package is not packaged on Conda, then a recipe should be created for it,
either by hand or via a tool like Grayskull.

## Conda Instance

The first step is to activate the Conda instance that will be used to create the
environments. This is done via:

```sh
module load exfel mambaforge
```

This will initialise the Conda instance into the `base` environment which
provides `grayskull` and `conda-lock` which are used to create the environments.

The `base` environment should **only** be used for those two tools, it should
**not** have any user packages installed into it.

## Environments

An environment is created per European XFEL experiment cycle, this is done so
that previous environments are preserved for reproducibility. The files defining
the environments are stored `./environments/${CYCLE}`.

Each environment directory will have two or three files:

- `base.yml` - Conda environment file containing packages which are available
  on a Conda channel
- `custom.yml` - optional Conda environment file containing packages built from
  custom recipes (see [Custom Recipes](#custom-recipes))
- `conda-lock.yml` - file generated by `conda-lock` using the environment files
  as inputs

### Creating a New Environment

Environments are stored in `./environments/`, create a new directory there with
a name for your environment.

If a new cycle environment is being created, copy the `base.yml` and
`custom.yml` files from the previous cycle, and use those as a starting point.
Otherwise create a standard Conda environment file:

```yml
channels:
  - file://gpfs/exfel/sw/software/xfel_anaconda3/mambaforge-22.9/conda-bld
  - conda-forge
  - defaults
dependencies:
  - numpy  # for example
```

And place any dependencies under the `dependencies` section. Note that these are
Conda dependencies, from Conda channels, not from PyPI, so the package names may
differ.

Once all required dependencies have been added to the dependencies list, carry
on with the instructions in [Locking and
Environment](#locking-and-installing-an-environment).

### Modifying an Existing Environment

To add a new package to an existing environment, the package should be added to
the `base.yml` if is is an existing package on a Conda channel, or added to
`custom.yml` if it is a package where the recipe has to be created by us.

Once all required dependencies have been added to the dependencies list, carry
on with the instructions in [Locking and
Environment](#locking-and-installing-an-environment).

### Locking and Installing an Environment

The following command can be used to concretize the environment and update or
create `conda-lock.yml`:

```sh
conda-lock \
  -f base.yml \
  -f custom.yml \
  --lockfile conda-lock.yml \  # Only if updating an existing environment
  -p linux-64
```

If the locking completes successfully, you should **add and commit the file**
with a description of the changes made in the commit message. Then you can then
update/install the environment via:

```sh
conda-lock install --name ${ENV_NAME} ./conda-lock.yml
```

## Custom Recipes

If a package does not already have a Conda recipe and is only available on PyPI
or via a repository URL, then a recipe should be made for it to allow for
installation into the Conda environments.

Creation of the recipes can be automated via
[Grayskull](https://github.com/conda-incubator/grayskull), which attempt to
convert the package setup to a Conda recipe, and implement some basic testing as
part of the build phase (check that importing the package works, tests that
entry points work), and also run
[conda-verify](https://github.com/conda/conda-verify) to check package
correctness.

Once a recipe has been created, the package must be built and added to a
directory that the relevant environment indexes. This can be done with `conda
mambabuild ...` (more info in next section), which will attempt to build the
package and execute any tests that are included in the recipe.

If Grayskull fails to create a valid recipe, then the Conda documentation on
creating recipes should be checked.

### Creating a Recipe

Recipes can be created via the Grayskull CLI:

```sh
grayskull pypi --recursive ${PYPI_NAME_OR_URL}
```

The `--recursive` flag is used to tell Grayskull to generate recipes for any
dependencies of the package which are also not in a Conda channel.

Note that the argument can be either:

- The name of the package on PyPI, which **must** contain an `sdist` as those
  are used to generate the recipes
- The URL to a hosted git repository, with a tag or release. If none is
  specified it will default to using the `latest` tag, which **must** exist
- The path to a `sdist` archive

If the package has releases on PyPI with `sdists`, then grayskull has a good
chance of working successfully. However if the package does not have a proper
release then some additional work has to be done.

In the 'worst case' scenario where a package has no releases or tags, and is not
on PyPI with an `sdist`, then you must build the `sdist` manually. To do this:

1. Clone the package
2. Create a gztar sdist - `python3 setup.py sdist --formats=gztar`
3. Run grayskull on the sdist archive - `grayskull pypi ./${PATH_TO_SDIST}`

A full example of this is:

```sh
git clone https://github.com/mhantke/h5writer/
cd h5writer
python3 setup.py sdist --formats=gztar
grayskull pypi ./h5writer-0.8.0
```

Additionally, there are issues with the generation of recipes for packages that
use `flit` as the build system. For these you need to edit the `meta.yaml` file
and add `flit-core` as a requirement manually.

### Building the Recipes

Once a new recipe is created, it must be built to create an installable package.

If the Conda installation the package is being built for is new, you will have
to tell it to use the build target directory as a channel, so that any packages
you have built will be installable.

```sh
conda config --add channels ${BUILD_DIRECTORY}
conda index ${BUILD_DIRECTORY}
```

As it has better performance, Boa (`mambabuild`) is used for the build process:

```sh
conda mambabuild \
  --skip-existing \  # Do not re-build already built packages
  --python 3.9 \  # Set python version for build
  --numpy 1.23 \  # Set numpy version for build
  --no-anaconda-upload \  # Do not attempt to upload package
  -c file://${BUILD_DIRECTORY} \  # Build target directory
  --use-local ${RECIPE_DIRECTORY}  # Recipe directory
```

If the build runs successfully, then the package will be placed into the build
directory, and it will be installable by the Conda instance as the directory is
an indexed channel.

If the build was not successful, then the package should be moved out of the
`recipes` directory, and can be added to a `broken` directory while it is being
fixed. If this is not done then future builds will fail as they the Conda build
process builds **all** recipes in the directory, not just a single package.
